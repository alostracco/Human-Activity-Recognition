{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Model Definition and Initial Training\n",
    "This notebook focuses on defining and training sequence models (LSTM and RNN) for human activity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from data_preparation import prepare_data_for_models\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_data_for_models()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model Definition and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 100, 64)           17408     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100, 64)           0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,982\n",
      "Trainable params: 54,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "276/276 - 21s - loss: 1.4886 - accuracy: 0.3934 - val_loss: 1.4422 - val_accuracy: 0.4161 - 21s/epoch - 75ms/step\n",
      "Epoch 2/50\n",
      "276/276 - 15s - loss: 1.3314 - accuracy: 0.4774 - val_loss: 1.2574 - val_accuracy: 0.5608 - 15s/epoch - 54ms/step\n",
      "Epoch 3/50\n",
      "276/276 - 16s - loss: 1.2857 - accuracy: 0.5171 - val_loss: 1.2192 - val_accuracy: 0.5617 - 16s/epoch - 57ms/step\n",
      "Epoch 4/50\n",
      "276/276 - 15s - loss: 1.2485 - accuracy: 0.5420 - val_loss: 1.2459 - val_accuracy: 0.5250 - 15s/epoch - 54ms/step\n",
      "Epoch 5/50\n",
      "276/276 - 16s - loss: 1.2374 - accuracy: 0.5426 - val_loss: 1.2289 - val_accuracy: 0.5281 - 16s/epoch - 59ms/step\n",
      "Epoch 6/50\n",
      "276/276 - 17s - loss: 1.2229 - accuracy: 0.5556 - val_loss: 1.2627 - val_accuracy: 0.5127 - 17s/epoch - 61ms/step\n",
      "Epoch 7/50\n",
      "276/276 - 42s - loss: 1.3159 - accuracy: 0.5008 - val_loss: 1.4483 - val_accuracy: 0.4469 - 42s/epoch - 152ms/step\n",
      "Epoch 8/50\n",
      "276/276 - 48s - loss: 1.2689 - accuracy: 0.5341 - val_loss: 1.1833 - val_accuracy: 0.5803 - 48s/epoch - 172ms/step\n",
      "Epoch 9/50\n",
      "276/276 - 46s - loss: 1.2475 - accuracy: 0.5362 - val_loss: 1.2070 - val_accuracy: 0.5490 - 46s/epoch - 165ms/step\n",
      "Epoch 10/50\n",
      "276/276 - 29s - loss: 1.2060 - accuracy: 0.5662 - val_loss: 1.1921 - val_accuracy: 0.5667 - 29s/epoch - 106ms/step\n",
      "Epoch 11/50\n",
      "276/276 - 15s - loss: 1.2185 - accuracy: 0.5557 - val_loss: 1.1823 - val_accuracy: 0.5622 - 15s/epoch - 56ms/step\n",
      "Epoch 12/50\n",
      "276/276 - 15s - loss: 1.1427 - accuracy: 0.5889 - val_loss: 1.1905 - val_accuracy: 0.5590 - 15s/epoch - 53ms/step\n",
      "Epoch 13/50\n",
      "276/276 - 15s - loss: 1.1545 - accuracy: 0.5889 - val_loss: 1.0973 - val_accuracy: 0.6071 - 15s/epoch - 54ms/step\n",
      "Epoch 14/50\n",
      "276/276 - 15s - loss: 1.0181 - accuracy: 0.6564 - val_loss: 0.8984 - val_accuracy: 0.7019 - 15s/epoch - 55ms/step\n",
      "Epoch 15/50\n",
      "276/276 - 16s - loss: 0.8894 - accuracy: 0.7045 - val_loss: 0.8164 - val_accuracy: 0.7432 - 16s/epoch - 56ms/step\n",
      "Epoch 16/50\n",
      "276/276 - 15s - loss: 0.7925 - accuracy: 0.7362 - val_loss: 0.7780 - val_accuracy: 0.7423 - 15s/epoch - 56ms/step\n",
      "Epoch 17/50\n",
      "276/276 - 15s - loss: 0.7679 - accuracy: 0.7426 - val_loss: 0.7402 - val_accuracy: 0.7423 - 15s/epoch - 56ms/step\n",
      "Epoch 18/50\n",
      "276/276 - 16s - loss: 0.7202 - accuracy: 0.7557 - val_loss: 0.6580 - val_accuracy: 0.7858 - 16s/epoch - 57ms/step\n",
      "Epoch 19/50\n",
      "276/276 - 15s - loss: 0.6553 - accuracy: 0.7772 - val_loss: 0.8648 - val_accuracy: 0.7191 - 15s/epoch - 56ms/step\n",
      "Epoch 20/50\n",
      "276/276 - 15s - loss: 0.6202 - accuracy: 0.7832 - val_loss: 0.7149 - val_accuracy: 0.7486 - 15s/epoch - 56ms/step\n",
      "Epoch 21/50\n",
      "276/276 - 16s - loss: 0.5680 - accuracy: 0.8016 - val_loss: 0.4832 - val_accuracy: 0.8339 - 16s/epoch - 57ms/step\n",
      "Epoch 22/50\n",
      "276/276 - 16s - loss: 0.4964 - accuracy: 0.8196 - val_loss: 0.4415 - val_accuracy: 0.8403 - 16s/epoch - 58ms/step\n",
      "Epoch 23/50\n",
      "276/276 - 16s - loss: 0.4304 - accuracy: 0.8489 - val_loss: 0.3893 - val_accuracy: 0.8625 - 16s/epoch - 57ms/step\n",
      "Epoch 24/50\n",
      "276/276 - 16s - loss: 0.3886 - accuracy: 0.8627 - val_loss: 0.3394 - val_accuracy: 0.8857 - 16s/epoch - 58ms/step\n",
      "Epoch 25/50\n",
      "276/276 - 16s - loss: 0.3984 - accuracy: 0.8624 - val_loss: 0.4212 - val_accuracy: 0.8643 - 16s/epoch - 57ms/step\n",
      "Epoch 26/50\n",
      "276/276 - 21s - loss: 0.3616 - accuracy: 0.8790 - val_loss: 0.3323 - val_accuracy: 0.8929 - 21s/epoch - 74ms/step\n",
      "Epoch 27/50\n",
      "276/276 - 16s - loss: 0.2973 - accuracy: 0.9014 - val_loss: 0.2957 - val_accuracy: 0.9002 - 16s/epoch - 58ms/step\n",
      "Epoch 28/50\n",
      "276/276 - 16s - loss: 0.3258 - accuracy: 0.8944 - val_loss: 0.2729 - val_accuracy: 0.9133 - 16s/epoch - 57ms/step\n",
      "Epoch 29/50\n",
      "276/276 - 16s - loss: 0.3205 - accuracy: 0.8938 - val_loss: 0.2858 - val_accuracy: 0.9093 - 16s/epoch - 56ms/step\n",
      "Epoch 30/50\n",
      "276/276 - 18s - loss: 0.2922 - accuracy: 0.9017 - val_loss: 0.3476 - val_accuracy: 0.8888 - 18s/epoch - 67ms/step\n",
      "Epoch 31/50\n",
      "276/276 - 19s - loss: 0.2789 - accuracy: 0.9059 - val_loss: 0.2589 - val_accuracy: 0.9152 - 19s/epoch - 67ms/step\n",
      "Epoch 32/50\n",
      "276/276 - 18s - loss: 0.2489 - accuracy: 0.9188 - val_loss: 0.2795 - val_accuracy: 0.9142 - 18s/epoch - 65ms/step\n",
      "Epoch 33/50\n",
      "276/276 - 18s - loss: 0.2370 - accuracy: 0.9200 - val_loss: 0.2288 - val_accuracy: 0.9247 - 18s/epoch - 66ms/step\n",
      "Epoch 34/50\n",
      "276/276 - 17s - loss: 0.2137 - accuracy: 0.9290 - val_loss: 0.2844 - val_accuracy: 0.9124 - 17s/epoch - 63ms/step\n",
      "Epoch 35/50\n",
      "276/276 - 16s - loss: 0.2449 - accuracy: 0.9186 - val_loss: 0.2542 - val_accuracy: 0.9247 - 16s/epoch - 56ms/step\n",
      "Epoch 36/50\n",
      "276/276 - 16s - loss: 0.2234 - accuracy: 0.9275 - val_loss: 0.2167 - val_accuracy: 0.9351 - 16s/epoch - 57ms/step\n",
      "Epoch 37/50\n",
      "276/276 - 16s - loss: 0.2056 - accuracy: 0.9322 - val_loss: 0.1747 - val_accuracy: 0.9433 - 16s/epoch - 59ms/step\n",
      "Epoch 38/50\n",
      "276/276 - 16s - loss: 0.1914 - accuracy: 0.9363 - val_loss: 0.2272 - val_accuracy: 0.9251 - 16s/epoch - 56ms/step\n",
      "Epoch 39/50\n",
      "276/276 - 16s - loss: 0.1763 - accuracy: 0.9408 - val_loss: 0.1830 - val_accuracy: 0.9401 - 16s/epoch - 56ms/step\n",
      "Epoch 40/50\n",
      "276/276 - 16s - loss: 0.1715 - accuracy: 0.9469 - val_loss: 0.1585 - val_accuracy: 0.9437 - 16s/epoch - 57ms/step\n",
      "Epoch 41/50\n",
      "276/276 - 16s - loss: 0.1628 - accuracy: 0.9476 - val_loss: 0.1822 - val_accuracy: 0.9451 - 16s/epoch - 58ms/step\n",
      "Epoch 42/50\n",
      "276/276 - 16s - loss: 0.1551 - accuracy: 0.9503 - val_loss: 0.1496 - val_accuracy: 0.9492 - 16s/epoch - 57ms/step\n",
      "Epoch 43/50\n",
      "276/276 - 16s - loss: 0.1589 - accuracy: 0.9473 - val_loss: 0.1928 - val_accuracy: 0.9387 - 16s/epoch - 58ms/step\n",
      "Epoch 44/50\n",
      "276/276 - 17s - loss: 0.1339 - accuracy: 0.9579 - val_loss: 0.1716 - val_accuracy: 0.9465 - 17s/epoch - 61ms/step\n",
      "Epoch 45/50\n",
      "276/276 - 16s - loss: 0.1417 - accuracy: 0.9521 - val_loss: 0.1758 - val_accuracy: 0.9451 - 16s/epoch - 57ms/step\n",
      "Epoch 46/50\n",
      "276/276 - 16s - loss: 0.1462 - accuracy: 0.9558 - val_loss: 0.1230 - val_accuracy: 0.9628 - 16s/epoch - 57ms/step\n",
      "Epoch 47/50\n",
      "276/276 - 16s - loss: 0.1347 - accuracy: 0.9561 - val_loss: 0.1327 - val_accuracy: 0.9601 - 16s/epoch - 57ms/step\n",
      "Epoch 48/50\n",
      "276/276 - 20s - loss: 0.1223 - accuracy: 0.9621 - val_loss: 0.1340 - val_accuracy: 0.9610 - 20s/epoch - 73ms/step\n",
      "Epoch 49/50\n",
      "276/276 - 17s - loss: 0.1351 - accuracy: 0.9567 - val_loss: 0.1245 - val_accuracy: 0.9651 - 17s/epoch - 62ms/step\n",
      "Epoch 50/50\n",
      "276/276 - 16s - loss: 0.1329 - accuracy: 0.9586 - val_loss: 0.1439 - val_accuracy: 0.9601 - 16s/epoch - 58ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "lstm_model.summary()\n",
    "\n",
    "lstm_history = lstm_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "lstm_model.save('../models/lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model Definition and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 100, 64)           4352      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 100, 64)           0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,158\n",
      "Trainable params: 17,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "276/276 [==============================] - 12s 33ms/step - loss: 1.3745 - accuracy: 0.4888 - val_loss: 1.0984 - val_accuracy: 0.6742\n",
      "Epoch 2/50\n",
      "276/276 [==============================] - 8s 31ms/step - loss: 1.0963 - accuracy: 0.6509 - val_loss: 0.8691 - val_accuracy: 0.7246\n",
      "Epoch 3/50\n",
      "276/276 [==============================] - 8s 31ms/step - loss: 0.8783 - accuracy: 0.7104 - val_loss: 0.9901 - val_accuracy: 0.5721\n",
      "Epoch 4/50\n",
      "276/276 [==============================] - 8s 30ms/step - loss: 0.7739 - accuracy: 0.7444 - val_loss: 0.7680 - val_accuracy: 0.7418\n",
      "Epoch 5/50\n",
      "276/276 [==============================] - 8s 31ms/step - loss: 0.6837 - accuracy: 0.7730 - val_loss: 0.6021 - val_accuracy: 0.7990\n",
      "Epoch 6/50\n",
      "276/276 [==============================] - 9s 32ms/step - loss: 0.6881 - accuracy: 0.7645 - val_loss: 0.6150 - val_accuracy: 0.7890\n",
      "Epoch 7/50\n",
      "276/276 [==============================] - 9s 33ms/step - loss: 0.7156 - accuracy: 0.7603 - val_loss: 1.6949 - val_accuracy: 0.4165\n",
      "Epoch 8/50\n",
      "276/276 [==============================] - 9s 33ms/step - loss: 1.4696 - accuracy: 0.4192 - val_loss: 1.5240 - val_accuracy: 0.4038\n",
      "Epoch 9/50\n",
      "276/276 [==============================] - 9s 31ms/step - loss: 1.2962 - accuracy: 0.5209 - val_loss: 1.1763 - val_accuracy: 0.6261\n",
      "Epoch 10/50\n",
      "276/276 [==============================] - 8s 30ms/step - loss: 0.9956 - accuracy: 0.6732 - val_loss: 0.8231 - val_accuracy: 0.7278\n",
      "Epoch 11/50\n",
      "276/276 [==============================] - 8s 30ms/step - loss: 0.9832 - accuracy: 0.6760 - val_loss: 0.8354 - val_accuracy: 0.7609\n",
      "Epoch 12/50\n",
      "276/276 [==============================] - 8s 31ms/step - loss: 0.8669 - accuracy: 0.7191 - val_loss: 0.8265 - val_accuracy: 0.7300\n",
      "Epoch 13/50\n",
      "276/276 [==============================] - 8s 31ms/step - loss: 0.8815 - accuracy: 0.7071 - val_loss: 0.7566 - val_accuracy: 0.7341\n",
      "Epoch 14/50\n",
      "276/276 [==============================] - 8s 30ms/step - loss: 0.7943 - accuracy: 0.7363 - val_loss: 0.7617 - val_accuracy: 0.7668\n",
      "Epoch 15/50\n",
      "276/276 [==============================] - 9s 32ms/step - loss: 0.9427 - accuracy: 0.6751 - val_loss: 1.1928 - val_accuracy: 0.5794\n",
      "Epoch 16/50\n",
      "276/276 [==============================] - 8s 31ms/step - loss: 1.1722 - accuracy: 0.6024 - val_loss: 1.0091 - val_accuracy: 0.6361\n",
      "Epoch 17/50\n",
      "276/276 [==============================] - 8s 31ms/step - loss: 1.0076 - accuracy: 0.6563 - val_loss: 0.8835 - val_accuracy: 0.7210\n",
      "Epoch 18/50\n",
      "276/276 [==============================] - 9s 32ms/step - loss: 0.9030 - accuracy: 0.6939 - val_loss: 0.7891 - val_accuracy: 0.7473\n",
      "Epoch 19/50\n",
      "276/276 [==============================] - 8s 31ms/step - loss: 0.9364 - accuracy: 0.6804 - val_loss: 0.7764 - val_accuracy: 0.7591\n",
      "Epoch 20/50\n",
      "276/276 [==============================] - 8s 30ms/step - loss: 1.5786 - accuracy: 0.4155 - val_loss: 1.4610 - val_accuracy: 0.4188\n",
      "Epoch 21/50\n",
      "276/276 [==============================] - 8s 31ms/step - loss: 1.4865 - accuracy: 0.3944 - val_loss: 1.4481 - val_accuracy: 0.4201\n",
      "Epoch 22/50\n",
      "276/276 [==============================] - 8s 31ms/step - loss: 1.5031 - accuracy: 0.3968 - val_loss: 1.5013 - val_accuracy: 0.3140\n",
      "Epoch 23/50\n",
      "276/276 [==============================] - 8s 30ms/step - loss: 1.4679 - accuracy: 0.4184 - val_loss: 1.3808 - val_accuracy: 0.4560\n",
      "Epoch 24/50\n",
      "276/276 [==============================] - 8s 30ms/step - loss: 1.4485 - accuracy: 0.4195 - val_loss: 1.4273 - val_accuracy: 0.4787\n",
      "Epoch 25/50\n",
      "276/276 [==============================] - 8s 30ms/step - loss: 1.3827 - accuracy: 0.4496 - val_loss: 1.7917 - val_accuracy: 0.2945\n",
      "Epoch 26/50\n",
      "276/276 [==============================] - 8s 30ms/step - loss: 1.3813 - accuracy: 0.4547 - val_loss: 1.3118 - val_accuracy: 0.5304\n",
      "Epoch 27/50\n",
      "276/276 [==============================] - 9s 33ms/step - loss: 1.3261 - accuracy: 0.4850 - val_loss: 1.3110 - val_accuracy: 0.4891\n",
      "Epoch 28/50\n",
      "276/276 [==============================] - 8s 29ms/step - loss: 1.2738 - accuracy: 0.5309 - val_loss: 1.2048 - val_accuracy: 0.5799\n",
      "Epoch 29/50\n",
      "276/276 [==============================] - 7s 27ms/step - loss: 1.0517 - accuracy: 0.6614 - val_loss: 0.9777 - val_accuracy: 0.6960\n",
      "Epoch 30/50\n",
      "276/276 [==============================] - 7s 27ms/step - loss: 1.0473 - accuracy: 0.6573 - val_loss: 0.9613 - val_accuracy: 0.6869\n",
      "Epoch 31/50\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.0065 - accuracy: 0.6798 - val_loss: 1.0143 - val_accuracy: 0.6919\n",
      "Epoch 32/50\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.2496 - accuracy: 0.5727 - val_loss: 1.4761 - val_accuracy: 0.4469\n",
      "Epoch 33/50\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.4926 - accuracy: 0.4086 - val_loss: 1.4283 - val_accuracy: 0.4710\n",
      "Epoch 34/50\n",
      "276/276 [==============================] - 7s 27ms/step - loss: 1.4325 - accuracy: 0.4426 - val_loss: 1.3775 - val_accuracy: 0.4896\n",
      "Epoch 35/50\n",
      "276/276 [==============================] - 8s 28ms/step - loss: 1.3406 - accuracy: 0.4699 - val_loss: 1.2604 - val_accuracy: 0.5304\n",
      "Epoch 36/50\n",
      "276/276 [==============================] - 8s 30ms/step - loss: 1.3066 - accuracy: 0.5058 - val_loss: 1.1889 - val_accuracy: 0.5821\n",
      "Epoch 37/50\n",
      "276/276 [==============================] - 9s 31ms/step - loss: 1.1233 - accuracy: 0.6096 - val_loss: 0.9808 - val_accuracy: 0.6701\n",
      "Epoch 38/50\n",
      "276/276 [==============================] - 9s 33ms/step - loss: 1.1970 - accuracy: 0.5804 - val_loss: 1.2728 - val_accuracy: 0.5535\n",
      "Epoch 39/50\n",
      "276/276 [==============================] - 7s 27ms/step - loss: 1.2854 - accuracy: 0.5268 - val_loss: 1.1223 - val_accuracy: 0.6152\n",
      "Epoch 40/50\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.3664 - accuracy: 0.4975 - val_loss: 1.4734 - val_accuracy: 0.3630\n",
      "Epoch 41/50\n",
      "276/276 [==============================] - 8s 28ms/step - loss: 1.2882 - accuracy: 0.5428 - val_loss: 1.3859 - val_accuracy: 0.5191\n",
      "Epoch 42/50\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.2496 - accuracy: 0.5531 - val_loss: 1.1656 - val_accuracy: 0.5839\n",
      "Epoch 43/50\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.3112 - accuracy: 0.5109 - val_loss: 1.2687 - val_accuracy: 0.5218\n",
      "Epoch 44/50\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.3037 - accuracy: 0.4994 - val_loss: 1.2652 - val_accuracy: 0.5299\n",
      "Epoch 45/50\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.2021 - accuracy: 0.5795 - val_loss: 1.0514 - val_accuracy: 0.6683\n",
      "Epoch 46/50\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.3268 - accuracy: 0.5016 - val_loss: 1.2191 - val_accuracy: 0.5676\n",
      "Epoch 47/50\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.3318 - accuracy: 0.4934 - val_loss: 1.3172 - val_accuracy: 0.4973\n",
      "Epoch 48/50\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.2734 - accuracy: 0.5405 - val_loss: 1.2605 - val_accuracy: 0.5431\n",
      "Epoch 49/50\n",
      "276/276 [==============================] - 7s 25ms/step - loss: 1.2247 - accuracy: 0.5594 - val_loss: 1.2399 - val_accuracy: 0.5163\n",
      "Epoch 50/50\n",
      "276/276 [==============================] - 7s 26ms/step - loss: 1.1901 - accuracy: 0.5788 - val_loss: 1.1567 - val_accuracy: 0.6093\n"
     ]
    }
   ],
   "source": [
    "rnn_model = Sequential([\n",
    "    SimpleRNN(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "rnn_model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "rnn_model.summary()\n",
    "\n",
    "rnn_history = rnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "rnn_model.save('../models/rnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook defined and performed initial training of both LSTM and RNN models for human activity recognition. The trained models were saved for further evaluation [here](model_training_evaluation.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
