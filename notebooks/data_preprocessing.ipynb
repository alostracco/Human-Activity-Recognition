{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "The dataset used below was downloaded from kaggle (https://www.kaggle.com/datasets/die9origephit/human-activity-recognition/data)\n",
    "\n",
    "This section of the code imports necessary packages:\n",
    "\n",
    "1. Loads the data set from the sensor_data.csv using it's relative path and storing it in a pandas object\n",
    "2. Removes any instances in the data that are missing information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user activity      timestamp  x-axis  y-axis  z-axis\n",
      "0     1  Walking  4991922345000    0.69   10.80   -2.03\n",
      "1     1  Walking  4991972333000    6.85    7.44   -0.50\n",
      "2     1  Walking  4992022351000    0.93    5.63   -0.50\n",
      "3     1  Walking  4992072339000   -2.11    5.01   -0.69\n",
      "4     1  Walking  4992122358000   -4.59    4.29   -1.95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "# Loads data using relative path\n",
    "data = pd.read_csv(\"../data/sensor_data.csv\")\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization using Min-Max Scaling\n",
    "\n",
    "This section normalizes the data by executing the following steps:\n",
    "\n",
    "1. Removing any data instances with missing values.\n",
    "2. Normalizing the position values.\n",
    "3. Encoding the activity labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  activity      timestamp    x-axis    y-axis    z-axis\n",
      "0     1         5  4991922345000  0.513145  0.766961  0.450901\n",
      "1     1         5  4991972333000  0.668857  0.682219  0.489723\n",
      "2     1         5  4992022351000  0.519211  0.636570  0.489723\n",
      "3     1         5  4992072339000  0.442366  0.620933  0.484902\n",
      "4     1         5  4992122358000  0.379676  0.602774  0.452931\n",
      "\n",
      "\n",
      "Activity Encoding Legend:\n",
      "Downstairs: 0\n",
      "Jogging: 1\n",
      "Sitting: 2\n",
      "Standing: 3\n",
      "Upstairs: 4\n",
      "Walking: 5\n"
     ]
    }
   ],
   "source": [
    "# Removes any data instances with missing informaion\n",
    "data = data.dropna() \n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize x-axis, y-axis, z-axis columns\n",
    "data[['x-axis', 'y-axis', 'z-axis']] = scaler.fit_transform(data[['x-axis', 'y-axis', 'z-axis']])\n",
    "\n",
    "activities = data['activity']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data['activity'] = encoder.fit_transform(data['activity'])\n",
    "\n",
    "# Check the normalized data\n",
    "print(data.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "activity_catalog = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "\n",
    "# Print the catalog\n",
    "print(\"Activity Encoding Legend:\")\n",
    "for activity, encoded_value in activity_catalog.items():\n",
    "    print(f\"{activity}: {encoded_value}\")\n",
    "\n",
    "data.to_csv('preprocessed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Segmentation for Time Series Analysis\n",
    "\n",
    "This section segments into windows using the following steps:\n",
    "\n",
    "1. Defining the window size, 5 seconds or 100 iterations per window.\n",
    "2. Defining the stride length, 25% overlap\n",
    "2. Removing windows spread across more than one users or tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def segmentData(rawData, windowSize, stride):\n",
    "    segmentedData = []\n",
    "    labels = []  # To store user and activity information for each window\n",
    "    \n",
    "    # Loop through the entire dataset to create windows\n",
    "    for start in range(0, len(rawData) - windowSize + 1, stride):\n",
    "        window = rawData.iloc[start:start + windowSize]\n",
    "        \n",
    "        # Check if the window contains only one activity\n",
    "        uniqueActivities = window['activity'].unique()\n",
    "        \n",
    "        # Check if the window contains only one user\n",
    "        uniqueUsers = window['user'].unique()\n",
    "\n",
    "        # Discards window if it contains more than one activity or more than one user\n",
    "        if len(uniqueActivities) > 1 or len(uniqueUsers) > 1:\n",
    "            continue  \n",
    "\n",
    "        # If the window contains only one activity and one user, add it to the list\n",
    "        segmentedData.append(window)\n",
    "        \n",
    "        # Store user and activity information for each window\n",
    "        labels.append({\n",
    "            'user': uniqueUsers[0],  # There should be only one user per window\n",
    "            'activity': uniqueActivities[0],  # There should be only one activity per window\n",
    "            'timestamp_start': window['timestamp'].iloc[0],  # Start timestamp of the window\n",
    "            'timestamp_end': window['timestamp'].iloc[-1]  # End timestamp of the window\n",
    "        })\n",
    "    \n",
    "    return segmentedData, labels\n",
    "\n",
    "# Parameters for windowing\n",
    "stride = 75\n",
    "windowSize = 100\n",
    "\n",
    "# Apply segmentation\n",
    "segmentedData, labels = segmentData(data, windowSize, stride)\n",
    "\n",
    "# Convert segmentedData to numpy array (accelerometer data only)\n",
    "segmentedDataArray = np.array([window[['x-axis', 'y-axis', 'z-axis']].values for window in segmentedData])\n",
    "\n",
    "# Save the segmented data to a .npy file\n",
    "np.save('segmented_data.npy', segmentedDataArray)\n",
    "\n",
    "# Save the labels to a CSV file\n",
    "labels_df = pd.DataFrame(labels)\n",
    "labels_df.to_csv('segmented_labels.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
