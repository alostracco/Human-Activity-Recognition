{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "This notebook focuses on continuing the training of the [sequence models](sequence_modeling.ipynb) (LSTM and RNN), evaluating their performance, and documenting the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "data = pd.read_csv('data/preprocessed_data.csv')\n",
    "\n",
    "# Split features and labels\n",
    "X = data.drop('activity_label', axis=1).values\n",
    "y = data['activity_label'].values\n",
    "\n",
    "# Reshape data for LSTM and RNN input\n",
    "time_steps = 100  # Example time step length\n",
    "num_features = X.shape[1] // time_steps\n",
    "X = X.reshape((-1, time_steps, num_features))\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the saved LSTM model\n",
    "lstm_model = load_model('models/lstm_model.h5')\n",
    "\n",
    "# Load the saved RNN model\n",
    "rnn_model = load_model('models/rnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training the LSTM model\n",
    "lstm_history = lstm_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=2)\n",
    "\n",
    "# Save the trained LSTM model\n",
    "lstm_model.save('models/final_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training the RNN model\n",
    "rnn_history = rnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=2)\n",
    "\n",
    "# Save the trained RNN model\n",
    "rnn_model.save('models/final_rnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data using LSTM model\n",
    "lstm_y_pred = lstm_model.predict(X_test)\n",
    "lstm_y_pred_classes = np.argmax(lstm_y_pred, axis=1)\n",
    "\n",
    "# Calculate performance metrics for LSTM model\n",
    "lstm_accuracy = accuracy_score(y_test, lstm_y_pred_classes)\n",
    "lstm_precision = precision_score(y_test, lstm_y_pred_classes, average='weighted')\n",
    "lstm_recall = recall_score(y_test, lstm_y_pred_classes, average='weighted')\n",
    "\n",
    "print(f'LSTM Model Accuracy: {lstm_accuracy}')\n",
    "print(f'LSTM Model Precision: {lstm_precision}')\n",
    "print(f'LSTM Model Recall: {lstm_recall}')\n",
    "\n",
    "# Confusion matrix for LSTM model\n",
    "lstm_conf_matrix = confusion_matrix(y_test, lstm_y_pred_classes)\n",
    "print('LSTM Model Confusion Matrix:')\n",
    "print(lstm_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data using RNN model\n",
    "rnn_y_pred = rnn_model.predict(X_test)\n",
    "rnn_y_pred_classes = np.argmax(rnn_y_pred, axis=1)\n",
    "\n",
    "# Calculate performance metrics for RNN model\n",
    "rnn_accuracy = accuracy_score(y_test, rnn_y_pred_classes)\n",
    "rnn_precision = precision_score(y_test, rnn_y_pred_classes, average='weighted')\n",
    "rnn_recall = recall_score(y_test, rnn_y_pred_classes, average='weighted')\n",
    "\n",
    "print(f'RNN Model Accuracy: {rnn_accuracy}')\n",
    "print(f'RNN Model Precision: {rnn_precision}')\n",
    "print(f'RNN Model Recall: {rnn_recall}')\n",
    "\n",
    "# Confusion matrix for RNN model\n",
    "rnn_conf_matrix = confusion_matrix(y_test, rnn_y_pred_classes)\n",
    "print('RNN Model Confusion Matrix:')\n",
    "print(rnn_conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values for LSTM\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(lstm_history.history['accuracy'])\n",
    "plt.plot(lstm_history.history['val_accuracy'])\n",
    "plt.title('LSTM Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values for LSTM\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(lstm_history.history['loss'])\n",
    "plt.plot(lstm_history.history['val_loss'])\n",
    "plt.title('LSTM Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values for RNN\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(rnn_history.history['accuracy'])\n",
    "plt.plot(rnn_history.history['val_accuracy'])\n",
    "plt.title('RNN Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values for RNN\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(rnn_history.history['loss'])\n",
    "plt.plot(rnn_history.history['val_loss'])\n",
    "plt.title('RNN Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook continued the training of the LSTM and RNN models, evaluated their performance, and documented the results. The models were assessed using accuracy, precision, recall, and confusion matrix metrics. The training processes and results were visualized to provide a clear understanding of the models' performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
